
# ğŸ“Œ Machine Learning & NLP Classification Project

## ğŸ“– Title & Short Description
This project focuses on applying **Natural Language Processing (NLP)** and **Supervised Machine Learning** techniques to classify text data into different categories. The primary goal is to evaluate and compare the performance of two widely used classification models:

- **Logistic Regression**
- **Random Forest Classifier**

These models are trained on TFâ€‘IDF vectorized text features. This task is important because text classification plays a crucial role in various modern applications like:

âœ… Sentiment analysis  
âœ… Spam detection  
âœ… Topic classification  
âœ… Customer feedback analytics  

---

## ğŸ“Š Dataset Source & Preprocessing
The dataset used in this project is a **userâ€‘provided CSV file** that contains:  
- A **text column**: natural language input
- A **categorical target label**: class for each text instance

### âœ… Preprocessing Applied:
- Removal of missing values
- TFâ€‘IDF vectorization of text for numerical representation
- Label Encoding for target column
- Trainâ€‘Test split (80% training / 20% testing)

No heavy filtering or cleaning was required, making the dataset suitable for baseline NLP experiments.

---

## ğŸ§  Methods & Approach

### ğŸ”¹ Technique Used
| Stage | Method |
|-------|-------|
| Text â†’ Numeric conversion | **TFâ€‘IDF Vectorizer** |
| Learning algorithms | **Logistic Regression** & **Random Forest** |
| Evaluation | Accuracy + Macro F1â€‘Score |

### âœ… Why This Approach?
- **TFâ€‘IDF** captures word importance and reduces noise
- **Logistic Regression** is a strong baseline for linear text classification tasks
- **Random Forest** captures nonâ€‘linear relationships and provides robust performance

We compared two fundamentally different modeling strategies to understand how linear vs. treeâ€‘based classifiers behave on the same text data.

---

## â–¶ï¸ Steps to Run the Code

### ğŸ”§ Requirements Installation
```bash
pip install pandas scikit-learn
```

### â–¶ï¸ Run the Script
```bash
python your_script.py
```

OR inside Jupyter/Colab simply execute all cells.

---

## ğŸ§ª Experiments & Results Summary

The models were evaluated using:

- âœ… Accuracy  
- âœ… Macro F1â€‘Score (balanced metric for multiple classes)

| Model | Accuracy | F1â€‘Score (Macro) |
|--------|:-------:|:---------------:|
| Logistic Regression | High performance on linear separable text | Performs very well |
| Random Forest | Competitive accuracy | Slightly lower than LR for sparse vectors |

> ğŸ“Œ Visualization techniques such as bar charts and tables were used to gain insight into model performance.

âœ… Logistic Regression performed slightly better overall due to the sparse nature of TFâ€‘IDF vectors.  
âœ… Random Forest still remained a strong alternative with robust generalization ability.

---

## âœ… Conclusion

From this project, we learned that:
- TFâ€‘IDF is an effective technique for transforming textual data into numerical features
- Logistic Regression tends to perform best on sparse, highâ€‘dimensional NLP datasets
- Random Forest still holds strong performance without complex hyperparameter tuning

ğŸ“Œ Future improvements may include:
- Advanced text cleaning (lemmatization, stopword removal)
- Hyperparameter tuning (GridSearch/RandomSearch)
- Deep Learning models such as BERT or LSTMs
- Visualization of feature importances and confusion matrices

---

## ğŸ“š References
1ï¸âƒ£ Scikitâ€‘Learn Documentation: https://scikit-learn.org  
2ï¸âƒ£ TFâ€‘IDF Article: https://en.wikipedia.org/wiki/Tfâ€“idf  
3ï¸âƒ£ Logistic Regression in ML: https://developers.google.com/machine-learning  
4ï¸âƒ£ Random Forest: Breiman, L. (2001). Machine Learning Journal  

---

âœ… Project completed using **Python, NLP & Machine Learning Models**  
